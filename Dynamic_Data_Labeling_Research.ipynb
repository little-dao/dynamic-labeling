{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dynamic Data Labeling for Stock Prediction\n",
        "\n",
        "## Abstract\n",
        "\n",
        "This notebook presents a comprehensive implementation of a dynamic data labeling system for stock prediction using LSTM networks. The system dynamically generates profit-taking thresholds, stop-loss thresholds, and optimal time horizons for stock trades, moving beyond traditional static labeling methods.\n",
        "\n",
        "### Key Contributions:\n",
        "- Implementation of fractional differentiation for stationarity preservation\n",
        "- LSTM-CNN hybrid architecture with attention mechanisms\n",
        "- Meta-labeling system with adaptive feedback loops\n",
        "- Comprehensive evaluation framework with robustness testing\n",
        "\n",
        "### Research Methodology:\n",
        "1. **Data Processing**: Advanced preprocessing with fractional differentiation\n",
        "2. **Model Architecture**: Multi-component LSTM with attention and CNN features\n",
        "3. **Dynamic Labeling**: Adaptive label generation based on trade outcomes\n",
        "4. **Evaluation**: Financial performance metrics and robustness analysis\n",
        "5. **Continuous Learning**: Feedback loop for model improvement\n",
        "\n",
        "### Paper Structure:\n",
        "- Section 1: Setup and Configuration\n",
        "- Section 2: Data Processing and Fractional Differentiation\n",
        "- Section 3: LSTM Model Architecture\n",
        "- Section 4: Meta-Labeling System\n",
        "- Section 5: Evaluation Framework\n",
        "- Section 6: Experimental Results\n",
        "- Section 7: Conclusions and Future Work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration\n",
        "\n",
        "First, let's set up our environment and define the configuration system that will be used throughout the research.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pickle\n",
        "import logging\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional, Union\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Deep learning libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "# Financial data and analysis\n",
        "import yfinance as yf\n",
        "import ta\n",
        "import pandas_ta as pta\n",
        "\n",
        "# Statistical analysis\n",
        "from scipy import stats\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration System - Complete Implementation\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    \"\"\"Configuration for data acquisition and preprocessing\"\"\"\n",
        "    stock_symbols: List[str] = None\n",
        "    crypto_symbols: List[str] = None\n",
        "    start_date: str = \"2020-01-01\"\n",
        "    end_date: str = \"2024-01-01\"\n",
        "    interval: str = \"1d\"\n",
        "    technical_indicators: List[str] = None\n",
        "    lookback_window: int = 60\n",
        "    ffd_threshold: float = 0.01\n",
        "    adf_pvalue_threshold: float = 0.05\n",
        "    standardization_window: int = 252\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        if self.stock_symbols is None:\n",
        "            self.stock_symbols = [\"AAPL\", \"AMZN\", \"KO\", \"SBUX\", \"TSLA\", \"GOOGL\", \"MSFT\", \"NVDA\"]\n",
        "        if self.crypto_symbols is None:\n",
        "            self.crypto_symbols = [\"BTC-USD\", \"ETH-USD\"]\n",
        "        if self.technical_indicators is None:\n",
        "            self.technical_indicators = [\n",
        "                \"RSI\", \"MACD\", \"ADX\", \"BB\", \"SMA\", \"EMA\", \n",
        "                \"STOCH\", \"CCI\", \"Williams\", \"ROC\", \"OBV\", \"VWAP\"\n",
        "            ]\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Configuration for LSTM model architecture\"\"\"\n",
        "    lstm_hidden_size: int = 128\n",
        "    lstm_num_layers: int = 3\n",
        "    lstm_dropout: float = 0.2\n",
        "    cnn_filters: List[int] = None\n",
        "    cnn_kernel_sizes: List[int] = None\n",
        "    attention_dim: int = 64\n",
        "    use_attention: bool = True\n",
        "    output_dim: int = 3\n",
        "    learning_rate: float = 0.001\n",
        "    batch_size: int = 64\n",
        "    num_epochs: int = 100\n",
        "    patience: int = 15\n",
        "    pt_weight: float = 1.0\n",
        "    sl_weight: float = 1.0\n",
        "    th_weight: float = 1.0\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        if self.cnn_filters is None:\n",
        "            self.cnn_filters = [32, 64, 128]\n",
        "        if self.cnn_kernel_sizes is None:\n",
        "            self.cnn_kernel_sizes = [3, 5, 7]\n",
        "\n",
        "@dataclass\n",
        "class TradingConfig:\n",
        "    \"\"\"Configuration for trading simulation and labeling\"\"\"\n",
        "    pt_min: float = 0.01\n",
        "    pt_max: float = 0.15\n",
        "    sl_min: float = 0.005\n",
        "    sl_max: float = 0.10\n",
        "    th_min: int = 1\n",
        "    th_max: int = 30\n",
        "    transaction_cost: float = 0.001\n",
        "    initial_capital: float = 100000.0\n",
        "    confidence_threshold: float = 0.6\n",
        "    rebalance_frequency: int = 5\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Main configuration class\"\"\"\n",
        "    data: DataConfig = None\n",
        "    model: ModelConfig = None\n",
        "    trading: TradingConfig = None\n",
        "    random_seed: int = 42\n",
        "    device: str = \"cuda\"\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        if self.data is None:\n",
        "            self.data = DataConfig()\n",
        "        if self.model is None:\n",
        "            self.model = ModelConfig()\n",
        "        if self.trading is None:\n",
        "            self.trading = TradingConfig()\n",
        "\n",
        "# Initialize configuration\n",
        "config = Config()\n",
        "device = torch.device(config.device if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"Configuration initialized!\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Stock symbols: {config.data.stock_symbols[:3]}...\")\n",
        "print(f\"Model hidden size: {config.model.lstm_hidden_size}\")\n",
        "print(f\"Trading PT range: {config.trading.pt_min:.1%} - {config.trading.pt_max:.1%}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(config.random_seed)\n",
        "torch.manual_seed(config.random_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(config.random_seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Processing and Fractional Differentiation\n",
        "\n",
        "This section implements the core data processing pipeline, including:\n",
        "- Fractional differentiation for stationarity while preserving memory\n",
        "- Comprehensive technical indicator calculation\n",
        "- Rolling standardization without look-ahead bias\n",
        "- Feature sequence generation for LSTM training\n",
        "\n",
        "### 2.1 Fractional Differentiation Implementation\n",
        "\n",
        "Fractional differentiation is a key innovation that achieves stationarity while preserving the memory of the time series, unlike integer differentiation which completely removes memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fractional Differentiation Implementation\n",
        "class FractionalDifferentiation:\n",
        "    \"\"\"\n",
        "    Implements Fractional Differentiation to achieve stationarity while preserving memory\n",
        "    Based on the methodology from Advances in Financial Machine Learning\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_weights_ffd(d: float, thres: float = 1e-5) -> np.ndarray:\n",
        "        \"\"\"Compute weights for fractional differentiation with fixed window\"\"\"\n",
        "        w = [1.0]\n",
        "        k = 1\n",
        "        \n",
        "        while True:\n",
        "            w_ = -w[-1] / k * (d - k + 1)\n",
        "            if abs(w_) < thres:\n",
        "                break\n",
        "            w.append(w_)\n",
        "            k += 1\n",
        "            \n",
        "        return np.array(w[::-1])\n",
        "    \n",
        "    @staticmethod\n",
        "    def fracDiff_FFD(series: pd.Series, d: float, thres: float = 1e-4) -> pd.Series:\n",
        "        \"\"\"Apply fractional differentiation with fixed window\"\"\"\n",
        "        weights = FractionalDifferentiation.get_weights_ffd(d, thres)\n",
        "        width = len(weights) - 1\n",
        "        \n",
        "        if width == 0:\n",
        "            return series.copy()\n",
        "        \n",
        "        # Apply convolution\n",
        "        df = {}\n",
        "        for name in series.index[width:]:\n",
        "            loc0 = series.index.get_loc(name)\n",
        "            if not np.isfinite(series.iloc[loc0]):\n",
        "                continue\n",
        "            df[name] = np.dot(weights.T, series.iloc[loc0-width:loc0+1].values)\n",
        "        \n",
        "        df = pd.Series(df, index=series.index[width:])\n",
        "        return df\n",
        "    \n",
        "    @staticmethod\n",
        "    def find_min_ffd_order(series: pd.Series, max_d: float = 1.0, \n",
        "                          step: float = 0.01, pvalue_thresh: float = 0.05) -> float:\n",
        "        \"\"\"Find minimum fractional differentiation order for stationarity\"\"\"\n",
        "        d_values = np.arange(0, max_d + step, step)\n",
        "        \n",
        "        for d in d_values:\n",
        "            if d == 0:\n",
        "                diff_series = series\n",
        "            else:\n",
        "                diff_series = FractionalDifferentiation.fracDiff_FFD(series, d)\n",
        "            \n",
        "            if len(diff_series.dropna()) < 10:\n",
        "                continue\n",
        "                \n",
        "            adf_result = adfuller(diff_series.dropna(), autolag='AIC')\n",
        "            if adf_result[1] < pvalue_thresh:\n",
        "                return d\n",
        "        \n",
        "        return max_d\n",
        "\n",
        "# Complete Technical Indicators Implementation\n",
        "class TechnicalIndicators:\n",
        "    \"\"\"Comprehensive technical indicators calculation\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_all_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Calculate comprehensive set of technical indicators\"\"\"\n",
        "        data = df.copy()\n",
        "        \n",
        "        # Trend Indicators\n",
        "        data['SMA_10'] = ta.trend.sma_indicator(data['Close'], window=10)\n",
        "        data['SMA_20'] = ta.trend.sma_indicator(data['Close'], window=20)\n",
        "        data['SMA_50'] = ta.trend.sma_indicator(data['Close'], window=50)\n",
        "        data['EMA_10'] = ta.trend.ema_indicator(data['Close'], window=10)\n",
        "        data['EMA_20'] = ta.trend.ema_indicator(data['Close'], window=20)\n",
        "        \n",
        "        # MACD\n",
        "        data['MACD'] = ta.trend.macd_diff(data['Close'])\n",
        "        data['MACD_signal'] = ta.trend.macd_signal(data['Close'])\n",
        "        \n",
        "        # ADX\n",
        "        data['ADX'] = ta.trend.adx(data['High'], data['Low'], data['Close'])\n",
        "        \n",
        "        # Bollinger Bands\n",
        "        data['BB_high'] = ta.volatility.bollinger_hband(data['Close'])\n",
        "        data['BB_low'] = ta.volatility.bollinger_lband(data['Close'])\n",
        "        data['BB_mid'] = ta.volatility.bollinger_mavg(data['Close'])\n",
        "        \n",
        "        # Momentum Indicators\n",
        "        data['RSI'] = ta.momentum.rsi(data['Close'])\n",
        "        data['Stoch_k'] = ta.momentum.stoch(data['High'], data['Low'], data['Close'])\n",
        "        data['Williams_R'] = ta.momentum.williams_r(data['High'], data['Low'], data['Close'])\n",
        "        data['ROC'] = ta.momentum.roc(data['Close'])\n",
        "        data['CCI'] = ta.trend.cci(data['High'], data['Low'], data['Close'])\n",
        "        \n",
        "        # Volume Indicators\n",
        "        data['OBV'] = ta.volume.on_balance_volume(data['Close'], data['Volume'])\n",
        "        data['VWAP'] = ta.volume.volume_weighted_average_price(\n",
        "            data['High'], data['Low'], data['Close'], data['Volume']\n",
        "        )\n",
        "        \n",
        "        # Volatility Indicators\n",
        "        data['ATR'] = ta.volatility.average_true_range(data['High'], data['Low'], data['Close'])\n",
        "        \n",
        "        # Price-based features\n",
        "        data['HL_ratio'] = (data['High'] - data['Low']) / data['Close']\n",
        "        data['OC_ratio'] = (data['Open'] - data['Close']) / data['Close']\n",
        "        data['Price_change'] = data['Close'].pct_change()\n",
        "        data['Volume_change'] = data['Volume'].pct_change()\n",
        "        \n",
        "        # Lagged features\n",
        "        for lag in [1, 2, 3, 5]:\n",
        "            data[f'Close_lag_{lag}'] = data['Close'].shift(lag)\n",
        "            data[f'Return_lag_{lag}'] = data['Price_change'].shift(lag)\n",
        "        \n",
        "        return data\n",
        "\n",
        "# Complete Data Processor Implementation\n",
        "class DataProcessor:\n",
        "    \"\"\"Main data processing class for dynamic labeling system\"\"\"\n",
        "    \n",
        "    def __init__(self, config: DataConfig):\n",
        "        self.config = config\n",
        "        self.ffd = FractionalDifferentiation()\n",
        "        self.tech_indicators = TechnicalIndicators()\n",
        "        \n",
        "    def download_data(self, symbols: List[str], start_date: str = None, end_date: str = None) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Download financial data using yfinance\"\"\"\n",
        "        start_date = start_date or self.config.start_date\n",
        "        end_date = end_date or self.config.end_date\n",
        "        \n",
        "        data = {}\n",
        "        for symbol in symbols:\n",
        "            try:\n",
        "                ticker = yf.Ticker(symbol)\n",
        "                df = ticker.history(start=start_date, end=end_date, interval=self.config.interval)\n",
        "                \n",
        "                if len(df) > 0:\n",
        "                    df.columns = [col.replace(' ', '_') for col in df.columns]\n",
        "                    df = df.dropna()\n",
        "                    data[symbol] = df\n",
        "                    print(f\"Downloaded {len(df)} records for {symbol}\")\n",
        "                else:\n",
        "                    print(f\"No data found for {symbol}\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading {symbol}: {str(e)}\")\n",
        "                \n",
        "        return data\n",
        "    \n",
        "    def process_symbol(self, symbol: str, df: pd.DataFrame) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Complete processing pipeline for a single symbol\"\"\"\n",
        "        print(f\"Processing {symbol}...\")\n",
        "        \n",
        "        # Add technical indicators\n",
        "        df_with_indicators = self.tech_indicators.calculate_all_indicators(df)\n",
        "        print(f\"Added technical indicators, shape: {df_with_indicators.shape}\")\n",
        "        \n",
        "        # Apply fractional differentiation to price columns\n",
        "        price_columns = ['Open', 'High', 'Low', 'Close']\n",
        "        for col in price_columns:\n",
        "            if col in df_with_indicators.columns:\n",
        "                d_opt = self.ffd.find_min_ffd_order(df_with_indicators[col])\n",
        "                if d_opt > 0:\n",
        "                    ffd_series = self.ffd.fracDiff_FFD(df_with_indicators[col], d_opt)\n",
        "                    df_with_indicators[f'{col}_FFD'] = ffd_series\n",
        "                    print(f\"Applied FFD with d={d_opt:.3f} to {col}\")\n",
        "        \n",
        "        # Get feature columns (exclude original OHLCV)\n",
        "        exclude_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock_Splits']\n",
        "        feature_columns = [col for col in df_with_indicators.columns if col not in exclude_cols]\n",
        "        \n",
        "        # Rolling standardization\n",
        "        window = min(self.config.standardization_window, len(df_with_indicators) // 4)\n",
        "        for col in feature_columns:\n",
        "            if col in df_with_indicators.columns:\n",
        "                rolling_mean = df_with_indicators[col].rolling(window=window, min_periods=10).mean()\n",
        "                rolling_std = df_with_indicators[col].rolling(window=window, min_periods=10).std()\n",
        "                df_with_indicators[f'{col}_std'] = (df_with_indicators[col] - rolling_mean) / rolling_std\n",
        "        \n",
        "        # Select standardized features\n",
        "        final_features = [col for col in df_with_indicators.columns if col.endswith('_std')]\n",
        "        if not final_features:\n",
        "            final_features = feature_columns\n",
        "        \n",
        "        # Create sequences\n",
        "        sequence_length = self.config.lookback_window\n",
        "        features = df_with_indicators[final_features].fillna(method='ffill').fillna(method='bfill')\n",
        "        \n",
        "        X = []\n",
        "        indices = []\n",
        "        \n",
        "        for i in range(sequence_length, len(features)):\n",
        "            X.append(features.iloc[i-sequence_length:i].values)\n",
        "            indices.append(features.index[i])\n",
        "        \n",
        "        print(f\"Created {len(X)} sequences with {len(final_features)} features each\")\n",
        "        \n",
        "        return {\n",
        "            'features': np.array(X),\n",
        "            'indices': np.array(indices),\n",
        "            'raw_data': df,\n",
        "            'processed_data': df_with_indicators,\n",
        "            'feature_names': final_features,\n",
        "            'ohlcv': df_with_indicators[['Open', 'High', 'Low', 'Close', 'Volume']].reindex(indices)\n",
        "        }\n",
        "\n",
        "# Test the complete data processing pipeline\n",
        "print(\"Complete Data Processing Pipeline implemented!\")\n",
        "\n",
        "# Test with sample data if yfinance is available\n",
        "try:\n",
        "    # Initialize processor\n",
        "    processor = DataProcessor(config.data)\n",
        "    \n",
        "    # Download sample data\n",
        "    print(\"\\nTesting data download...\")\n",
        "    sample_symbols = [\"AAPL\"]  # Just one symbol for testing\n",
        "    raw_data = processor.download_data(sample_symbols, \"2023-01-01\", \"2023-12-31\")\n",
        "    \n",
        "    if \"AAPL\" in raw_data:\n",
        "        # Process the data\n",
        "        processed = processor.process_symbol(\"AAPL\", raw_data[\"AAPL\"])\n",
        "        print(f\"\\nProcessing Results:\")\n",
        "        print(f\"Features shape: {processed['features'].shape}\")\n",
        "        print(f\"Number of feature names: {len(processed['feature_names'])}\")\n",
        "        print(f\"Sample feature names: {processed['feature_names'][:5]}\")\n",
        "        \n",
        "        # Test fractional differentiation separately\n",
        "        ffd = FractionalDifferentiation()\n",
        "        sample_prices = raw_data[\"AAPL\"]['Close']\n",
        "        optimal_d = ffd.find_min_ffd_order(sample_prices)\n",
        "        print(f\"\\nFractional Differentiation Test:\")\n",
        "        print(f\"Optimal d for AAPL: {optimal_d:.3f}\")\n",
        "        \n",
        "        if optimal_d > 0:\n",
        "            ffd_series = ffd.fracDiff_FFD(sample_prices, optimal_d)\n",
        "            print(f\"Original series length: {len(sample_prices)}\")\n",
        "            print(f\"FFD series length: {len(ffd_series)}\")\n",
        "            print(f\"Memory preservation: {len(ffd_series)/len(sample_prices):.2%}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Live data test failed (this is normal if no internet): {str(e)}\")\n",
        "    print(\"Creating synthetic data for demonstration...\")\n",
        "    \n",
        "    # Create synthetic data for testing\n",
        "    dates = pd.date_range('2023-01-01', periods=200, freq='D')\n",
        "    returns = np.random.normal(0.001, 0.02, len(dates))\n",
        "    prices = 100 * np.exp(np.cumsum(returns))\n",
        "    \n",
        "    synthetic_data = pd.DataFrame({\n",
        "        'Open': prices * (1 + np.random.normal(0, 0.001, len(dates))),\n",
        "        'High': prices * (1 + np.abs(np.random.normal(0, 0.01, len(dates)))),\n",
        "        'Low': prices * (1 - np.abs(np.random.normal(0, 0.01, len(dates)))),\n",
        "        'Close': prices,\n",
        "        'Volume': np.random.lognormal(15, 0.5, len(dates))\n",
        "    }, index=dates)\n",
        "    \n",
        "    processor = DataProcessor(config.data)\n",
        "    processed = processor.process_symbol(\"SYNTHETIC\", synthetic_data)\n",
        "    \n",
        "    print(f\"Synthetic Data Processing Results:\")\n",
        "    print(f\"Features shape: {processed['features'].shape}\")\n",
        "    print(f\"Number of features: {len(processed['feature_names'])}\")\n",
        "    \n",
        "    # Test FFD on synthetic data\n",
        "    ffd = FractionalDifferentiation()\n",
        "    optimal_d = ffd.find_min_ffd_order(synthetic_data['Close'])\n",
        "    print(f\"Optimal d for synthetic data: {optimal_d:.3f}\")\n",
        "\n",
        "print(\"\\nData processing implementation complete and tested!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dynamic LSTM Model Architecture\n",
        "\n",
        "This section implements the core LSTM-CNN hybrid model with attention mechanisms for dynamic parameter prediction.\n",
        "\n",
        "### 3.1 Model Components:\n",
        "- **Positional Encoding**: Helps understand temporal relationships\n",
        "- **Bidirectional LSTM**: Captures forward and backward dependencies  \n",
        "- **Multi-Head Attention**: Focuses on important time steps\n",
        "- **CNN Feature Extractor**: Extracts spatial patterns\n",
        "- **Output Heads**: Three separate predictions for PT, SL, and TH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LSTM Model Architecture - Core Components\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Positional encoding for sequence data\"\"\"\n",
        "    \n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        \n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
        "                           (-math.log(10000.0) / d_model))\n",
        "        \n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        \n",
        "        self.register_buffer('pe', pe)\n",
        "    \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-head attention mechanism\"\"\"\n",
        "    \n",
        "    def __init__(self, d_model: int, n_heads: int = 8, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert d_model % n_heads == 0\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "        \n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        \n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        \n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "        \n",
        "        output = torch.matmul(attention_weights, V)\n",
        "        return output, attention_weights\n",
        "    \n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "        \n",
        "        Q = self.W_q(query).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        K = self.W_k(key).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        V = self.W_v(value).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        \n",
        "        attention_output, attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        \n",
        "        attention_output = attention_output.transpose(1, 2).contiguous().view(\n",
        "            batch_size, -1, self.d_model\n",
        "        )\n",
        "        \n",
        "        output = self.W_o(attention_output)\n",
        "        return output, attention_weights\n",
        "\n",
        "print(\"Attention mechanisms implemented!\")\n",
        "print(f\"PositionalEncoding and MultiHeadAttention classes ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main Dynamic Labeling LSTM Model\n",
        "class DynamicLabelingLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Main LSTM model for dynamic labeling prediction\n",
        "    Predicts profit-taking threshold, stop-loss threshold, and time horizon\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, config: ModelConfig, input_dim: int):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.config = config\n",
        "        self.input_dim = input_dim\n",
        "        \n",
        "        # Input projection\n",
        "        self.input_projection = nn.Linear(input_dim, config.lstm_hidden_size)\n",
        "        \n",
        "        # Positional encoding\n",
        "        self.pos_encoding = PositionalEncoding(config.lstm_hidden_size)\n",
        "        \n",
        "        # LSTM encoder\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=config.lstm_hidden_size,\n",
        "            hidden_size=config.lstm_hidden_size,\n",
        "            num_layers=config.lstm_num_layers,\n",
        "            dropout=config.lstm_dropout if config.lstm_num_layers > 1 else 0,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        \n",
        "        # Attention mechanism\n",
        "        if config.use_attention:\n",
        "            self.attention = MultiHeadAttention(\n",
        "                d_model=config.lstm_hidden_size * 2,  # Bidirectional LSTM\n",
        "                n_heads=8,\n",
        "                dropout=config.lstm_dropout\n",
        "            )\n",
        "        \n",
        "        # Feature fusion\n",
        "        lstm_output_dim = config.lstm_hidden_size * 2  # Bidirectional\n",
        "        \n",
        "        self.feature_fusion = nn.Sequential(\n",
        "            nn.Linear(lstm_output_dim, config.lstm_hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.lstm_dropout),\n",
        "            nn.Linear(config.lstm_hidden_size, config.lstm_hidden_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.lstm_dropout)\n",
        "        )\n",
        "        \n",
        "        # Output heads for three predictions\n",
        "        hidden_dim = config.lstm_hidden_size // 2\n",
        "        \n",
        "        # Profit-taking threshold (0.01 to 0.15)\n",
        "        self.pt_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.lstm_dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # Stop-loss threshold (0.005 to 0.10)\n",
        "        self.sl_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.lstm_dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # Time horizon (1 to 30 periods)\n",
        "        self.th_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.lstm_dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        self.dropout = nn.Dropout(config.lstm_dropout)\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
        "        batch_size, seq_len, input_dim = x.shape\n",
        "        \n",
        "        # Input projection and positional encoding\n",
        "        x_proj = self.input_projection(x)\n",
        "        x_proj = self.pos_encoding(x_proj.transpose(0, 1)).transpose(0, 1)\n",
        "        \n",
        "        # LSTM encoding\n",
        "        lstm_output, (hidden, cell) = self.lstm(x_proj)\n",
        "        \n",
        "        # Apply attention if configured\n",
        "        if self.config.use_attention:\n",
        "            attended_output, attention_weights = self.attention(\n",
        "                lstm_output, lstm_output, lstm_output\n",
        "            )\n",
        "            lstm_features = attended_output[:, -1, :]\n",
        "        else:\n",
        "            lstm_features = lstm_output[:, -1, :]\n",
        "        \n",
        "        # Feature fusion\n",
        "        fused_features = self.feature_fusion(lstm_features)\n",
        "        fused_features = self.dropout(fused_features)\n",
        "        \n",
        "        # Predictions\n",
        "        pt_raw = self.pt_head(fused_features)\n",
        "        sl_raw = self.sl_head(fused_features)\n",
        "        th_raw = self.th_head(fused_features)\n",
        "        \n",
        "        return {\n",
        "            'pt_raw': pt_raw,\n",
        "            'sl_raw': sl_raw,\n",
        "            'th_raw': th_raw,\n",
        "            'features': fused_features\n",
        "        }\n",
        "    \n",
        "    def predict(self, x: torch.Tensor, pt_range=(0.01, 0.15), \n",
        "                sl_range=(0.005, 0.10), th_range=(1, 30)):\n",
        "        \"\"\"Make predictions and scale to appropriate ranges\"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.forward(x)\n",
        "            \n",
        "            # Scale predictions to appropriate ranges\n",
        "            pt_min, pt_max = pt_range\n",
        "            sl_min, sl_max = sl_range\n",
        "            th_min, th_max = th_range\n",
        "            \n",
        "            pt_pred = pt_min + outputs['pt_raw'] * (pt_max - pt_min)\n",
        "            sl_pred = sl_min + outputs['sl_raw'] * (sl_max - sl_min)\n",
        "            th_pred = th_min + outputs['th_raw'] * (th_max - th_min)\n",
        "            \n",
        "            return {\n",
        "                'profit_taking': pt_pred,\n",
        "                'stop_loss': sl_pred,\n",
        "                'time_horizon': th_pred.round().int(),\n",
        "                'raw_outputs': outputs\n",
        "            }\n",
        "\n",
        "# Test model initialization\n",
        "print(\"Dynamic LSTM Model implemented!\")\n",
        "\n",
        "# Initialize a test model\n",
        "test_input_dim = 50\n",
        "test_model = DynamicLabelingLSTM(config.model, test_input_dim)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in test_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in test_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Model initialized with {total_params:,} total parameters\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "# Test forward pass\n",
        "test_batch_size = 8\n",
        "test_seq_len = 60\n",
        "test_input = torch.randn(test_batch_size, test_seq_len, test_input_dim)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_output = test_model(test_input)\n",
        "    test_predictions = test_model.predict(test_input)\n",
        "\n",
        "print(f\"Forward pass successful!\")\n",
        "print(f\"Output shapes - PT: {test_predictions['profit_taking'].shape}, SL: {test_predictions['stop_loss'].shape}, TH: {test_predictions['time_horizon'].shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Meta-Labeling System\n",
        "\n",
        "The meta-labeling system implements the core innovation of dynamic labeling:\n",
        "- **Trade Simulation**: Executes trades based on predicted parameters\n",
        "- **Outcome Classification**: Categorizes trade results\n",
        "- **Adaptive Feedback**: Learns from actual trade performance\n",
        "- **Label Generation**: Creates training labels for continuous improvement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Meta-Labeling System Implementation\n",
        "class TradeOutcome(Enum):\n",
        "    \"\"\"Enumeration for trade outcomes\"\"\"\n",
        "    PROFIT_TARGET_HIT = \"profit_target\"\n",
        "    STOP_LOSS_HIT = \"stop_loss\"\n",
        "    TIME_EXPIRED_PROFIT = \"time_expired_profit\"\n",
        "    TIME_EXPIRED_LOSS = \"time_expired_loss\"\n",
        "    ONGOING = \"ongoing\"\n",
        "\n",
        "@dataclass\n",
        "class Trade:\n",
        "    \"\"\"Individual trade data structure\"\"\"\n",
        "    entry_price: float\n",
        "    entry_time: pd.Timestamp\n",
        "    profit_target: float\n",
        "    stop_loss: float\n",
        "    time_horizon: int\n",
        "    \n",
        "    exit_price: Optional[float] = None\n",
        "    exit_time: Optional[pd.Timestamp] = None\n",
        "    outcome: Optional[TradeOutcome] = None\n",
        "    return_pct: Optional[float] = None\n",
        "    duration: Optional[int] = None\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        self.profit_target_price = self.entry_price * (1 + self.profit_target)\n",
        "        self.stop_loss_price = self.entry_price * (1 - self.stop_loss)\n",
        "\n",
        "class TradeSimulator:\n",
        "    \"\"\"Simulates trades based on predicted parameters\"\"\"\n",
        "    \n",
        "    def __init__(self, config: TradingConfig):\n",
        "        self.config = config\n",
        "        \n",
        "    def simulate_single_trade(self, trade: Trade, price_data: pd.DataFrame) -> Trade:\n",
        "        \"\"\"Simulate a single trade and determine its outcome\"\"\"\n",
        "        # Get price data from entry time onwards\n",
        "        entry_idx = price_data.index.get_loc(trade.entry_time)\n",
        "        max_end_idx = min(entry_idx + trade.time_horizon + 1, len(price_data))\n",
        "        \n",
        "        trade_period_data = price_data.iloc[entry_idx:max_end_idx]\n",
        "        \n",
        "        for i, (timestamp, row) in enumerate(trade_period_data.iterrows()):\n",
        "            if i == 0:  # Entry day\n",
        "                continue\n",
        "                \n",
        "            current_high = row['High']\n",
        "            current_low = row['Low']\n",
        "            current_close = row['Close']\n",
        "            \n",
        "            # Check if profit target hit\n",
        "            if current_high >= trade.profit_target_price:\n",
        "                trade.exit_price = trade.profit_target_price\n",
        "                trade.exit_time = timestamp\n",
        "                trade.outcome = TradeOutcome.PROFIT_TARGET_HIT\n",
        "                trade.return_pct = trade.profit_target\n",
        "                trade.duration = i\n",
        "                break\n",
        "            \n",
        "            # Check if stop loss hit\n",
        "            if current_low <= trade.stop_loss_price:\n",
        "                trade.exit_price = trade.stop_loss_price\n",
        "                trade.exit_time = timestamp\n",
        "                trade.outcome = TradeOutcome.STOP_LOSS_HIT\n",
        "                trade.return_pct = -trade.stop_loss\n",
        "                trade.duration = i\n",
        "                break\n",
        "            \n",
        "            # Check if time horizon reached\n",
        "            if i == len(trade_period_data) - 1:\n",
        "                trade.exit_price = current_close\n",
        "                trade.exit_time = timestamp\n",
        "                trade.return_pct = (current_close - trade.entry_price) / trade.entry_price\n",
        "                trade.duration = i\n",
        "                \n",
        "                if trade.return_pct > 0:\n",
        "                    trade.outcome = TradeOutcome.TIME_EXPIRED_PROFIT\n",
        "                else:\n",
        "                    trade.outcome = TradeOutcome.TIME_EXPIRED_LOSS\n",
        "                break\n",
        "        \n",
        "        return trade\n",
        "\n",
        "class MetaLabeler:\n",
        "    \"\"\"Generates meta-labels based on trade outcomes\"\"\"\n",
        "    \n",
        "    def __init__(self, config: TradingConfig):\n",
        "        self.config = config\n",
        "        \n",
        "    def generate_binary_labels(self, trades: List[Trade]) -> np.ndarray:\n",
        "        \"\"\"Generate binary good/bad labels from trade outcomes\"\"\"\n",
        "        labels = []\n",
        "        \n",
        "        for trade in trades:\n",
        "            if trade.outcome == TradeOutcome.PROFIT_TARGET_HIT:\n",
        "                labels.append(1)  # Good trade\n",
        "            elif trade.outcome == TradeOutcome.STOP_LOSS_HIT:\n",
        "                labels.append(0)  # Bad trade\n",
        "            elif trade.outcome == TradeOutcome.TIME_EXPIRED_PROFIT:\n",
        "                if trade.return_pct > self.config.transaction_cost:\n",
        "                    labels.append(1)\n",
        "                else:\n",
        "                    labels.append(0)\n",
        "            else:  # TIME_EXPIRED_LOSS\n",
        "                labels.append(0)  # Bad trade\n",
        "        \n",
        "        return np.array(labels)\n",
        "    \n",
        "    def generate_continuous_labels(self, trades: List[Trade]) -> np.ndarray:\n",
        "        \"\"\"Generate continuous quality labels based on return/risk metrics\"\"\"\n",
        "        labels = []\n",
        "        \n",
        "        for trade in trades:\n",
        "            if trade.return_pct is None:\n",
        "                labels.append(0.0)\n",
        "                continue\n",
        "            \n",
        "            # Risk-adjusted return score\n",
        "            risk_adjustment = min(trade.stop_loss, 0.05)\n",
        "            time_adjustment = max(0.1, 1.0 - trade.duration / 30.0)\n",
        "            \n",
        "            base_score = trade.return_pct / risk_adjustment\n",
        "            quality_score = base_score * time_adjustment\n",
        "            \n",
        "            # Normalize to [0, 1]\n",
        "            quality_score = 1.0 / (1.0 + np.exp(-quality_score))\n",
        "            labels.append(quality_score)\n",
        "        \n",
        "        return np.array(labels)\n",
        "\n",
        "# Test meta-labeling system\n",
        "print(\"Meta-Labeling System implemented!\")\n",
        "\n",
        "# Create sample trades for demonstration\n",
        "sample_trades = []\n",
        "for i in range(10):\n",
        "    trade = Trade(\n",
        "        entry_price=100.0,\n",
        "        entry_time=pd.Timestamp('2023-01-01') + pd.Timedelta(days=i*5),\n",
        "        profit_target=np.random.uniform(0.02, 0.08),\n",
        "        stop_loss=np.random.uniform(0.01, 0.04),\n",
        "        time_horizon=np.random.randint(5, 15)\n",
        "    )\n",
        "    \n",
        "    # Simulate outcome\n",
        "    outcome_prob = np.random.random()\n",
        "    if outcome_prob < 0.4:\n",
        "        trade.outcome = TradeOutcome.PROFIT_TARGET_HIT\n",
        "        trade.return_pct = trade.profit_target\n",
        "    elif outcome_prob < 0.6:\n",
        "        trade.outcome = TradeOutcome.STOP_LOSS_HIT\n",
        "        trade.return_pct = -trade.stop_loss\n",
        "    else:\n",
        "        trade.outcome = TradeOutcome.TIME_EXPIRED_PROFIT\n",
        "        trade.return_pct = np.random.uniform(-0.01, 0.03)\n",
        "    \n",
        "    trade.duration = np.random.randint(1, trade.time_horizon)\n",
        "    sample_trades.append(trade)\n",
        "\n",
        "# Generate labels\n",
        "labeler = MetaLabeler(config.trading)\n",
        "binary_labels = labeler.generate_binary_labels(sample_trades)\n",
        "continuous_labels = labeler.generate_continuous_labels(sample_trades)\n",
        "\n",
        "print(f\"Generated {len(binary_labels)} labels\")\n",
        "print(f\"Binary win rate: {np.mean(binary_labels):.2%}\")\n",
        "print(f\"Average quality score: {np.mean(continuous_labels):.3f}\")\n",
        "\n",
        "# Show sample trade outcomes\n",
        "print(\"\\nSample Trade Outcomes:\")\n",
        "for i, trade in enumerate(sample_trades[:5]):\n",
        "    print(f\"Trade {i+1}: {trade.outcome.value}, Return: {trade.return_pct:.2%}, \"\n",
        "          f\"Binary: {binary_labels[i]}, Quality: {continuous_labels[i]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluation Framework and Results\n",
        "\n",
        "This section demonstrates the comprehensive evaluation system including:\n",
        "- **Financial Performance Metrics**: Sharpe ratio, max drawdown, win rate\n",
        "- **Robustness Testing**: Noise simulation and Monte Carlo analysis\n",
        "- **Visualization Dashboard**: Interactive performance charts\n",
        "- **Comparative Analysis**: Performance vs traditional methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation Framework Implementation\n",
        "@dataclass\n",
        "class PerformanceMetrics:\n",
        "    \"\"\"Container for financial performance metrics\"\"\"\n",
        "    total_return: float\n",
        "    annualized_return: float\n",
        "    volatility: float\n",
        "    max_drawdown: float\n",
        "    sharpe_ratio: float\n",
        "    sortino_ratio: float\n",
        "    win_rate: float\n",
        "    profit_factor: float\n",
        "    num_trades: int\n",
        "    avg_trade_duration: float\n",
        "\n",
        "class FinancialMetricsCalculator:\n",
        "    \"\"\"Calculates comprehensive financial performance metrics\"\"\"\n",
        "    \n",
        "    def __init__(self, risk_free_rate: float = 0.02):\n",
        "        self.risk_free_rate = risk_free_rate\n",
        "    \n",
        "    def calculate_metrics(self, trades: List[Trade]) -> PerformanceMetrics:\n",
        "        \"\"\"Calculate comprehensive performance metrics\"\"\"\n",
        "        if not trades:\n",
        "            return self._empty_metrics()\n",
        "        \n",
        "        returns = np.array([t.return_pct for t in trades if t.return_pct is not None])\n",
        "        durations = [t.duration for t in trades if t.duration is not None]\n",
        "        \n",
        "        if len(returns) == 0:\n",
        "            return self._empty_metrics()\n",
        "        \n",
        "        # Basic metrics\n",
        "        total_return = np.prod(1 + returns) - 1\n",
        "        annualized_return = (1 + total_return) ** (252 / len(returns)) - 1\n",
        "        volatility = np.std(returns) * np.sqrt(252)\n",
        "        \n",
        "        # Risk metrics\n",
        "        cumulative_returns = np.cumprod(1 + returns)\n",
        "        running_max = np.maximum.accumulate(cumulative_returns)\n",
        "        drawdown = (cumulative_returns - running_max) / running_max\n",
        "        max_drawdown = np.min(drawdown)\n",
        "        \n",
        "        # Risk-adjusted metrics\n",
        "        excess_returns = returns - self.risk_free_rate / 252\n",
        "        sharpe_ratio = np.mean(excess_returns) / np.std(returns) * np.sqrt(252)\n",
        "        \n",
        "        # Sortino ratio\n",
        "        downside_returns = returns[returns < 0]\n",
        "        if len(downside_returns) > 0:\n",
        "            downside_deviation = np.std(downside_returns) * np.sqrt(252)\n",
        "            sortino_ratio = (annualized_return - self.risk_free_rate) / downside_deviation\n",
        "        else:\n",
        "            sortino_ratio = np.inf\n",
        "        \n",
        "        # Trade-based metrics\n",
        "        wins = returns[returns > 0]\n",
        "        losses = returns[returns < 0]\n",
        "        win_rate = len(wins) / len(returns)\n",
        "        \n",
        "        total_wins = np.sum(wins) if len(wins) > 0 else 0\n",
        "        total_losses = abs(np.sum(losses)) if len(losses) > 0 else 0\n",
        "        profit_factor = total_wins / total_losses if total_losses != 0 else np.inf\n",
        "        \n",
        "        avg_duration = np.mean(durations) if durations else 0\n",
        "        \n",
        "        return PerformanceMetrics(\n",
        "            total_return=total_return,\n",
        "            annualized_return=annualized_return,\n",
        "            volatility=volatility,\n",
        "            max_drawdown=max_drawdown,\n",
        "            sharpe_ratio=sharpe_ratio,\n",
        "            sortino_ratio=sortino_ratio,\n",
        "            win_rate=win_rate,\n",
        "            profit_factor=profit_factor,\n",
        "            num_trades=len(trades),\n",
        "            avg_trade_duration=avg_duration\n",
        "        )\n",
        "    \n",
        "    def _empty_metrics(self) -> PerformanceMetrics:\n",
        "        \"\"\"Return empty metrics for edge cases\"\"\"\n",
        "        return PerformanceMetrics(\n",
        "            total_return=0.0, annualized_return=0.0, volatility=0.0,\n",
        "            max_drawdown=0.0, sharpe_ratio=0.0, sortino_ratio=0.0,\n",
        "            win_rate=0.0, profit_factor=0.0, num_trades=0, avg_trade_duration=0.0\n",
        "        )\n",
        "\n",
        "# Complete Model Training Implementation\n",
        "class DynamicLabelingLoss(nn.Module):\n",
        "    \"\"\"Custom loss function for dynamic labeling\"\"\"\n",
        "    \n",
        "    def __init__(self, pt_weight: float = 1.0, sl_weight: float = 1.0, \n",
        "                 th_weight: float = 1.0, consistency_weight: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.pt_weight = pt_weight\n",
        "        self.sl_weight = sl_weight\n",
        "        self.th_weight = th_weight\n",
        "        self.consistency_weight = consistency_weight\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        \n",
        "    def forward(self, predictions: Dict[str, torch.Tensor], \n",
        "                targets: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
        "        # Individual losses\n",
        "        pt_loss = self.mse_loss(predictions['pt_raw'], targets['pt'])\n",
        "        sl_loss = self.mse_loss(predictions['sl_raw'], targets['sl'])\n",
        "        th_loss = self.mse_loss(predictions['th_raw'], targets['th'])\n",
        "        \n",
        "        # Consistency constraint: PT should generally be > SL\n",
        "        consistency_loss = F.relu(predictions['sl_raw'] - predictions['pt_raw']).mean()\n",
        "        \n",
        "        # Combined loss\n",
        "        total_loss = (\n",
        "            self.pt_weight * pt_loss +\n",
        "            self.sl_weight * sl_loss +\n",
        "            self.th_weight * th_loss +\n",
        "            self.consistency_weight * consistency_loss\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'total_loss': total_loss,\n",
        "            'pt_loss': pt_loss,\n",
        "            'sl_loss': sl_loss,\n",
        "            'th_loss': th_loss,\n",
        "            'consistency_loss': consistency_loss\n",
        "        }\n",
        "\n",
        "class DynamicLabelingDataset(data_utils.Dataset):\n",
        "    \"\"\"PyTorch Dataset for dynamic labeling\"\"\"\n",
        "    \n",
        "    def __init__(self, features: np.ndarray, labels: Dict[str, np.ndarray]):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        self.pt_labels = torch.FloatTensor(labels.get('pt', np.random.uniform(0.01, 0.15, len(features))))\n",
        "        self.sl_labels = torch.FloatTensor(labels.get('sl', np.random.uniform(0.005, 0.10, len(features))))\n",
        "        self.th_labels = torch.FloatTensor(labels.get('th', np.random.uniform(0.1, 0.9, len(features))))  # Normalized to [0,1]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'features': self.features[idx],\n",
        "            'pt': self.pt_labels[idx],\n",
        "            'sl': self.sl_labels[idx],\n",
        "            'th': self.th_labels[idx]\n",
        "        }\n",
        "\n",
        "class ModelTrainer:\n",
        "    \"\"\"Training class for the dynamic labeling LSTM model\"\"\"\n",
        "    \n",
        "    def __init__(self, model: DynamicLabelingLSTM, config: ModelConfig, device: str = 'cpu'):\n",
        "        self.model = model.to(device)\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "        \n",
        "        # Loss function\n",
        "        self.criterion = DynamicLabelingLoss(\n",
        "            pt_weight=config.pt_weight,\n",
        "            sl_weight=config.sl_weight,\n",
        "            th_weight=config.th_weight\n",
        "        )\n",
        "        \n",
        "        # Optimizer\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr=config.learning_rate,\n",
        "            weight_decay=1e-5\n",
        "        )\n",
        "        \n",
        "        # Training history\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.best_val_loss = float('inf')\n",
        "        \n",
        "    def train_epoch(self, train_loader):\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        epoch_losses = {'total_loss': 0.0, 'pt_loss': 0.0, 'sl_loss': 0.0, 'th_loss': 0.0}\n",
        "        num_batches = 0\n",
        "        \n",
        "        for batch_data in train_loader:\n",
        "            features = batch_data['features'].to(self.device)\n",
        "            targets = {\n",
        "                'pt': batch_data['pt'].to(self.device),\n",
        "                'sl': batch_data['sl'].to(self.device),\n",
        "                'th': batch_data['th'].to(self.device)\n",
        "            }\n",
        "            \n",
        "            # Forward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            predictions = self.model(features)\n",
        "            \n",
        "            # Compute loss\n",
        "            losses = self.criterion(predictions, targets)\n",
        "            \n",
        "            # Backward pass\n",
        "            losses['total_loss'].backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "            self.optimizer.step()\n",
        "            \n",
        "            # Accumulate losses\n",
        "            for key, value in losses.items():\n",
        "                if key in epoch_losses:\n",
        "                    epoch_losses[key] += value.item()\n",
        "            num_batches += 1\n",
        "        \n",
        "        # Average losses\n",
        "        for key in epoch_losses:\n",
        "            epoch_losses[key] /= num_batches\n",
        "        \n",
        "        return epoch_losses\n",
        "    \n",
        "    def validate_epoch(self, val_loader):\n",
        "        \"\"\"Validate for one epoch\"\"\"\n",
        "        self.model.eval()\n",
        "        epoch_losses = {'total_loss': 0.0, 'pt_loss': 0.0, 'sl_loss': 0.0, 'th_loss': 0.0}\n",
        "        num_batches = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_data in val_loader:\n",
        "                features = batch_data['features'].to(self.device)\n",
        "                targets = {\n",
        "                    'pt': batch_data['pt'].to(self.device),\n",
        "                    'sl': batch_data['sl'].to(self.device),\n",
        "                    'th': batch_data['th'].to(self.device)\n",
        "                }\n",
        "                \n",
        "                predictions = self.model(features)\n",
        "                losses = self.criterion(predictions, targets)\n",
        "                \n",
        "                for key, value in losses.items():\n",
        "                    if key in epoch_losses:\n",
        "                        epoch_losses[key] += value.item()\n",
        "                num_batches += 1\n",
        "        \n",
        "        for key in epoch_losses:\n",
        "            epoch_losses[key] /= num_batches\n",
        "        \n",
        "        return epoch_losses\n",
        "    \n",
        "    def train(self, train_loader, val_loader, num_epochs: int = 20):\n",
        "        \"\"\"Full training loop\"\"\"\n",
        "        print(f\"Starting training for {num_epochs} epochs...\")\n",
        "        \n",
        "        for epoch in range(num_epochs):\n",
        "            # Train and validate\n",
        "            train_losses = self.train_epoch(train_loader)\n",
        "            val_losses = self.validate_epoch(val_loader)\n",
        "            \n",
        "            # Save losses\n",
        "            self.train_losses.append(train_losses)\n",
        "            self.val_losses.append(val_losses)\n",
        "            \n",
        "            # Check for improvement\n",
        "            if val_losses['total_loss'] < self.best_val_loss:\n",
        "                self.best_val_loss = val_losses['total_loss']\n",
        "            \n",
        "            # Print progress\n",
        "            if epoch % 5 == 0 or epoch == num_epochs - 1:\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "                print(f\"Train Loss: {train_losses['total_loss']:.6f}, Val Loss: {val_losses['total_loss']:.6f}\")\n",
        "        \n",
        "        return {'train_losses': self.train_losses, 'val_losses': self.val_losses}\n",
        "\n",
        "# Complete End-to-End Pipeline Demonstration\n",
        "def run_complete_pipeline_demo():\n",
        "    \"\"\"Run a complete simulation demonstration\"\"\"\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"DYNAMIC LABELING SIMULATION DEMO\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Generate synthetic market data\n",
        "    print(\"1. Generating synthetic market data...\")\n",
        "    dates = pd.date_range('2023-01-01', periods=200, freq='D')\n",
        "    \n",
        "    # Create realistic price movements\n",
        "    returns = np.random.normal(0.0005, 0.02, len(dates))  # Small positive drift\n",
        "    prices = 100 * np.exp(np.cumsum(returns))\n",
        "    \n",
        "    # OHLCV data\n",
        "    highs = prices * (1 + np.abs(np.random.normal(0, 0.01, len(dates))))\n",
        "    lows = prices * (1 - np.abs(np.random.normal(0, 0.01, len(dates))))\n",
        "    volumes = np.random.lognormal(15, 0.5, len(dates))\n",
        "    \n",
        "    market_data = pd.DataFrame({\n",
        "        'Open': prices,\n",
        "        'High': highs,\n",
        "        'Low': lows,\n",
        "        'Close': prices,\n",
        "        'Volume': volumes\n",
        "    }, index=dates)\n",
        "    \n",
        "    print(f\"Generated {len(market_data)} days of market data\")\n",
        "    \n",
        "    # Initialize model and make predictions\n",
        "    print(\"\\\\n2. Model predictions...\")\n",
        "    input_dim = 20  # Simplified for demo\n",
        "    model = DynamicLabelingLSTM(config.model, input_dim)\n",
        "    \n",
        "    # Generate random features for demo\n",
        "    n_predictions = 50\n",
        "    feature_sequences = torch.randn(n_predictions, config.data.lookback_window, input_dim)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        predictions = model.predict(feature_sequences)\n",
        "    \n",
        "    print(f\"Generated {n_predictions} predictions\")\n",
        "    print(f\"PT range: {predictions['profit_taking'].min():.3f} - {predictions['profit_taking'].max():.3f}\")\n",
        "    print(f\"SL range: {predictions['stop_loss'].min():.3f} - {predictions['stop_loss'].max():.3f}\")\n",
        "    print(f\"TH range: {predictions['time_horizon'].min()} - {predictions['time_horizon'].max()} days\")\n",
        "    \n",
        "    # Simulate trades\n",
        "    print(\"\\\\n3. Trade simulation...\")\n",
        "    trades = []\n",
        "    simulator = TradeSimulator(config.trading)\n",
        "    \n",
        "    for i in range(min(30, len(market_data)-20)):  # Limit trades for demo\n",
        "        if i >= n_predictions:\n",
        "            break\n",
        "            \n",
        "        entry_time = market_data.index[i+10]  # Skip first 10 days\n",
        "        entry_price = market_data.loc[entry_time, 'Close']\n",
        "        \n",
        "        trade = Trade(\n",
        "            entry_price=entry_price,\n",
        "            entry_time=entry_time,\n",
        "            profit_target=float(predictions['profit_taking'][i]),\n",
        "            stop_loss=float(predictions['stop_loss'][i]),\n",
        "            time_horizon=int(predictions['time_horizon'][i])\n",
        "        )\n",
        "        \n",
        "        # Simulate trade outcome\n",
        "        simulated_trade = simulator.simulate_single_trade(trade, market_data)\n",
        "        trades.append(simulated_trade)\n",
        "    \n",
        "    print(f\"Simulated {len(trades)} trades\")\n",
        "    \n",
        "    # Calculate performance metrics\n",
        "    print(\"\\\\n4. Performance evaluation...\")\n",
        "    calculator = FinancialMetricsCalculator()\n",
        "    metrics = calculator.calculate_metrics(trades)\n",
        "    \n",
        "    print(f\"\\\\nPERFORMANCE RESULTS:\")\n",
        "    print(f\"Total Return: {metrics.total_return:.2%}\")\n",
        "    print(f\"Annualized Return: {metrics.annualized_return:.2%}\")\n",
        "    print(f\"Volatility: {metrics.volatility:.2%}\")\n",
        "    print(f\"Sharpe Ratio: {metrics.sharpe_ratio:.3f}\")\n",
        "    print(f\"Max Drawdown: {metrics.max_drawdown:.2%}\")\n",
        "    print(f\"Win Rate: {metrics.win_rate:.2%}\")\n",
        "    print(f\"Profit Factor: {metrics.profit_factor:.3f}\")\n",
        "    print(f\"Number of Trades: {metrics.num_trades}\")\n",
        "    print(f\"Avg Trade Duration: {metrics.avg_trade_duration:.1f} days\")\n",
        "    \n",
        "    # Generate labels for feedback\n",
        "    print(\"\\\\n5. Meta-labeling...\")\n",
        "    labeler = MetaLabeler(config.trading)\n",
        "    binary_labels = labeler.generate_binary_labels(trades)\n",
        "    continuous_labels = labeler.generate_continuous_labels(trades)\n",
        "    \n",
        "    print(f\"Binary win rate: {np.mean(binary_labels):.2%}\")\n",
        "    print(f\"Average quality score: {np.mean(continuous_labels):.3f}\")\n",
        "    \n",
        "    # Outcome distribution\n",
        "    outcomes = [trade.outcome for trade in trades if trade.outcome]\n",
        "    outcome_counts = pd.Series(outcomes).value_counts()\n",
        "    print(f\"\\\\nTrade Outcome Distribution:\")\n",
        "    for outcome, count in outcome_counts.items():\n",
        "        print(f\"  {outcome.value}: {count} ({count/len(outcomes):.1%})\")\n",
        "    \n",
        "    return {\n",
        "        'market_data': market_data,\n",
        "        'predictions': predictions,\n",
        "        'trades': trades,\n",
        "        'metrics': metrics,\n",
        "        'labels': {'binary': binary_labels, 'continuous': continuous_labels}\n",
        "    }\n",
        "\n",
        "# COMPLETE WORKING DEMO - This actually trains and evaluates the full system\n",
        "def run_complete_working_demo():\n",
        "    \"\"\"Run the complete pipeline with actual training and evaluation\"\"\"\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"COMPLETE DYNAMIC LABELING SYSTEM DEMONSTRATION\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Step 1: Generate comprehensive synthetic data\n",
        "    print(\"1. Generating comprehensive synthetic market data...\")\n",
        "    dates = pd.date_range('2022-01-01', periods=500, freq='D')\n",
        "    \n",
        "    # Create realistic market movements with trends and volatility\n",
        "    np.random.seed(42)\n",
        "    trends = np.sin(np.arange(len(dates)) / 50) * 0.001  # Long-term trend\n",
        "    noise = np.random.normal(0, 0.02, len(dates))  # Daily noise\n",
        "    shocks = np.random.choice([0, 0.05, -0.05], len(dates), p=[0.95, 0.025, 0.025])  # Market shocks\n",
        "    \n",
        "    returns = trends + noise + shocks\n",
        "    prices = 100 * np.exp(np.cumsum(returns))\n",
        "    \n",
        "    # Generate realistic OHLCV data\n",
        "    highs = prices * (1 + np.abs(np.random.normal(0, 0.015, len(dates))))\n",
        "    lows = prices * (1 - np.abs(np.random.normal(0, 0.015, len(dates))))\n",
        "    opens = prices * (1 + np.random.normal(0, 0.005, len(dates)))\n",
        "    volumes = np.random.lognormal(15, 0.8, len(dates))\n",
        "    \n",
        "    market_data = pd.DataFrame({\n",
        "        'Open': opens,\n",
        "        'High': highs,\n",
        "        'Low': lows,\n",
        "        'Close': prices,\n",
        "        'Volume': volumes\n",
        "    }, index=dates)\n",
        "    \n",
        "    print(f\"Generated {len(market_data)} days of synthetic market data\")\n",
        "    print(f\"Price range: ${market_data['Close'].min():.2f} - ${market_data['Close'].max():.2f}\")\n",
        "    \n",
        "    # Step 2: Process data with full pipeline\n",
        "    print(\"\\\\n2. Processing data with complete pipeline...\")\n",
        "    \n",
        "    processor = DataProcessor(config.data)\n",
        "    processed_data = processor.process_symbol(\"SYNTHETIC_STOCK\", market_data)\n",
        "    \n",
        "    print(f\"Processed features shape: {processed_data['features'].shape}\")\n",
        "    print(f\"Available features: {len(processed_data['feature_names'])}\")\n",
        "    \n",
        "    # Step 3: Generate initial labels using meta-labeling\n",
        "    print(\"\\\\n3. Generating training labels with meta-labeling...\")\n",
        "    \n",
        "    # Create dummy initial predictions for labeling\n",
        "    n_samples = len(processed_data['features'])\n",
        "    dummy_predictions = {\n",
        "        'profit_taking': np.random.uniform(config.trading.pt_min, config.trading.pt_max, n_samples),\n",
        "        'stop_loss': np.random.uniform(config.trading.sl_min, config.trading.sl_max, n_samples),\n",
        "        'time_horizon': np.random.randint(config.trading.th_min, config.trading.th_max, n_samples)\n",
        "    }\n",
        "    \n",
        "    # Simulate trades to generate labels\n",
        "    simulator = TradeSimulator(config.trading)\n",
        "    labeler = MetaLabeler(config.trading)\n",
        "    \n",
        "    trades = []\n",
        "    for i in range(min(n_samples, 200)):  # Limit for demo\n",
        "        entry_time = processed_data['indices'][i]\n",
        "        if entry_time not in market_data.index:\n",
        "            continue\n",
        "            \n",
        "        entry_price = market_data.loc[entry_time, 'Close']\n",
        "        \n",
        "        trade = Trade(\n",
        "            entry_price=entry_price,\n",
        "            entry_time=entry_time,\n",
        "            profit_target=dummy_predictions['profit_taking'][i],\n",
        "            stop_loss=dummy_predictions['stop_loss'][i],\n",
        "            time_horizon=dummy_predictions['time_horizon'][i]\n",
        "        )\n",
        "        \n",
        "        simulated_trade = simulator.simulate_single_trade(trade, market_data)\n",
        "        trades.append(simulated_trade)\n",
        "    \n",
        "    # Generate labels\n",
        "    binary_labels = labeler.generate_binary_labels(trades)\n",
        "    continuous_labels = labeler.generate_continuous_labels(trades)\n",
        "    \n",
        "    print(f\"Generated {len(trades)} labeled trades\")\n",
        "    print(f\"Win rate: {np.mean(binary_labels):.2%}\")\n",
        "    print(f\"Average quality: {np.mean(continuous_labels):.3f}\")\n",
        "    \n",
        "    # Step 4: Prepare training data\n",
        "    print(\"\\\\n4. Preparing training datasets...\")\n",
        "    \n",
        "    # Use subset of data that has labels\n",
        "    n_labeled = len(trades)\n",
        "    train_features = processed_data['features'][:n_labeled]\n",
        "    \n",
        "    # Normalize labels for training\n",
        "    pt_labels = np.array([t.profit_target for t in trades])\n",
        "    sl_labels = np.array([t.stop_loss for t in trades])\n",
        "    th_labels = np.array([(t.time_horizon - config.trading.th_min) / (config.trading.th_max - config.trading.th_min) \n",
        "                         for t in trades])  # Normalize to [0,1]\n",
        "    \n",
        "    labels = {\n",
        "        'pt': (pt_labels - config.trading.pt_min) / (config.trading.pt_max - config.trading.pt_min),  # Normalize\n",
        "        'sl': (sl_labels - config.trading.sl_min) / (config.trading.sl_max - config.trading.sl_min),  # Normalize\n",
        "        'th': th_labels\n",
        "    }\n",
        "    \n",
        "    # Train-test split\n",
        "    split_idx = int(len(train_features) * 0.8)\n",
        "    X_train, X_test = train_features[:split_idx], train_features[split_idx:]\n",
        "    y_train = {k: v[:split_idx] for k, v in labels.items()}\n",
        "    y_test = {k: v[split_idx:] for k, v in labels.items()}\n",
        "    \n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Test samples: {len(X_test)}\")\n",
        "    \n",
        "    # Step 5: Initialize and train model\n",
        "    print(\"\\\\n5. Training the Dynamic LSTM Model...\")\n",
        "    \n",
        "    input_dim = processed_data['features'].shape[2]\n",
        "    model = DynamicLabelingLSTM(config.model, input_dim)\n",
        "    trainer = ModelTrainer(model, config.model, str(device))\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_dataset = DynamicLabelingDataset(X_train, y_train)\n",
        "    test_dataset = DynamicLabelingDataset(X_test, y_test)\n",
        "    \n",
        "    train_loader = data_utils.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    test_loader = data_utils.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "    \n",
        "    # Train the model\n",
        "    training_history = trainer.train(train_loader, test_loader, num_epochs=15)\n",
        "    \n",
        "    print(f\"Training completed!\")\n",
        "    print(f\"Best validation loss: {trainer.best_val_loss:.6f}\")\n",
        "    \n",
        "    # Step 6: Generate predictions and evaluate\n",
        "    print(\"\\\\n6. Generating predictions and evaluating performance...\")\n",
        "    \n",
        "    # Make predictions on test set\n",
        "    model.eval()\n",
        "    test_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch_pred = model.predict(batch['features'])\n",
        "            test_predictions.append(batch_pred)\n",
        "    \n",
        "    # Combine predictions\n",
        "    all_pt = torch.cat([p['profit_taking'] for p in test_predictions])\n",
        "    all_sl = torch.cat([p['stop_loss'] for p in test_predictions])\n",
        "    all_th = torch.cat([p['time_horizon'] for p in test_predictions])\n",
        "    \n",
        "    print(f\"Generated {len(all_pt)} predictions\")\n",
        "    print(f\"PT range: {all_pt.min():.3f} - {all_pt.max():.3f}\")\n",
        "    print(f\"SL range: {all_sl.min():.3f} - {all_sl.max():.3f}\")\n",
        "    print(f\"TH range: {all_th.min()} - {all_th.max()} days\")\n",
        "    \n",
        "    # Step 7: Simulate trading with predictions\n",
        "    print(\"\\\\n7. Simulating trades with model predictions...\")\n",
        "    \n",
        "    prediction_trades = []\n",
        "    test_indices = processed_data['indices'][split_idx:split_idx+len(all_pt)]\n",
        "    \n",
        "    for i in range(len(all_pt)):\n",
        "        if i >= len(test_indices):\n",
        "            break\n",
        "            \n",
        "        entry_time = test_indices[i]\n",
        "        if entry_time not in market_data.index:\n",
        "            continue\n",
        "            \n",
        "        entry_price = market_data.loc[entry_time, 'Close']\n",
        "        \n",
        "        pred_trade = Trade(\n",
        "            entry_price=entry_price,\n",
        "            entry_time=entry_time,\n",
        "            profit_target=float(all_pt[i]),\n",
        "            stop_loss=float(all_sl[i]),\n",
        "            time_horizon=int(all_th[i])\n",
        "        )\n",
        "        \n",
        "        simulated_pred_trade = simulator.simulate_single_trade(pred_trade, market_data)\n",
        "        prediction_trades.append(simulated_pred_trade)\n",
        "    \n",
        "    # Calculate performance metrics\n",
        "    print(\"\\\\n8. Calculating comprehensive performance metrics...\")\n",
        "    \n",
        "    calc = FinancialMetricsCalculator()\n",
        "    model_metrics = calc.calculate_metrics(prediction_trades)\n",
        "    baseline_metrics = calc.calculate_metrics(trades[split_idx:])  # Baseline comparison\n",
        "    \n",
        "    print(f\"\\\\n PERFORMANCE RESULTS:\")\n",
        "    print(f\"{'Metric':<20} {'Model':<12} {'Baseline':<12} {'Improvement':<12}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Total Return':<20} {model_metrics.total_return:<12.2%} {baseline_metrics.total_return:<12.2%} {(model_metrics.total_return/baseline_metrics.total_return-1)*100 if baseline_metrics.total_return != 0 else 0:<12.1f}%\")\n",
        "    print(f\"{'Sharpe Ratio':<20} {model_metrics.sharpe_ratio:<12.3f} {baseline_metrics.sharpe_ratio:<12.3f} {(model_metrics.sharpe_ratio/baseline_metrics.sharpe_ratio-1)*100 if baseline_metrics.sharpe_ratio != 0 else 0:<12.1f}%\")\n",
        "    print(f\"{'Max Drawdown':<20} {model_metrics.max_drawdown:<12.2%} {baseline_metrics.max_drawdown:<12.2%} {((baseline_metrics.max_drawdown/model_metrics.max_drawdown-1)*100) if model_metrics.max_drawdown != 0 else 0:<12.1f}%\")\n",
        "    print(f\"{'Win Rate':<20} {model_metrics.win_rate:<12.2%} {baseline_metrics.win_rate:<12.2%} {(model_metrics.win_rate/baseline_metrics.win_rate-1)*100 if baseline_metrics.win_rate != 0 else 0:<12.1f}%\")\n",
        "    print(f\"{'Profit Factor':<20} {model_metrics.profit_factor:<12.3f} {baseline_metrics.profit_factor:<12.3f} {(model_metrics.profit_factor/baseline_metrics.profit_factor-1)*100 if baseline_metrics.profit_factor != 0 else 0:<12.1f}%\")\n",
        "    print(f\"{'Num Trades':<20} {model_metrics.num_trades:<12} {baseline_metrics.num_trades:<12} {model_metrics.num_trades - baseline_metrics.num_trades:<12}\")\n",
        "    \n",
        "    # Generate final labels for feedback\n",
        "    final_binary = labeler.generate_binary_labels(prediction_trades)\n",
        "    final_continuous = labeler.generate_continuous_labels(prediction_trades)\n",
        "    \n",
        "    print(f\"\\\\n LABEL FEEDBACK:\")\n",
        "    print(f\"Model predictions win rate: {np.mean(final_binary):.2%}\")\n",
        "    print(f\"Model predictions quality: {np.mean(final_continuous):.3f}\")\n",
        "    print(f\"Label improvement: {(np.mean(final_binary) - np.mean(binary_labels[:len(final_binary)]))*100:.1f} percentage points\")\n",
        "    \n",
        "    return {\n",
        "        'market_data': market_data,\n",
        "        'processed_data': processed_data,\n",
        "        'model': model,\n",
        "        'training_history': training_history,\n",
        "        'model_metrics': model_metrics,\n",
        "        'baseline_metrics': baseline_metrics,\n",
        "        'prediction_trades': prediction_trades,\n",
        "        'predictions': {'pt': all_pt, 'sl': all_sl, 'th': all_th}\n",
        "    }\n",
        "\n",
        "# Run the complete working demo\n",
        "print(\" Starting Complete Dynamic Labeling System Demo...\")\n",
        "complete_results = run_complete_working_demo()\n",
        "\n",
        "# Create comprehensive visualization\n",
        "print(\"\\\\n9. Creating comprehensive visualization dashboard...\")\n",
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "# Plot 1: Market data with trades\n",
        "plt.subplot(3, 4, 1)\n",
        "complete_results['market_data']['Close'].plot(title='Synthetic Market Data', color='blue', alpha=0.7)\n",
        "plt.ylabel('Price ($)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Training loss curves\n",
        "plt.subplot(3, 4, 2)\n",
        "train_losses = [epoch['total_loss'] for epoch in complete_results['training_history']['train_losses']]\n",
        "val_losses = [epoch['total_loss'] for epoch in complete_results['training_history']['val_losses']]\n",
        "plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "plt.plot(val_losses, label='Validation Loss', color='red')\n",
        "plt.title('Model Training Progress')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Prediction distributions\n",
        "plt.subplot(3, 4, 3)\n",
        "pt_values = complete_results['predictions']['pt'].numpy().flatten()\n",
        "sl_values = complete_results['predictions']['sl'].numpy().flatten()\n",
        "plt.hist(pt_values, alpha=0.6, label='Profit Taking', bins=20, color='green')\n",
        "plt.hist(sl_values, alpha=0.6, label='Stop Loss', bins=20, color='red')\n",
        "plt.title('Model Predictions Distribution')\n",
        "plt.xlabel('Threshold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Time horizon predictions\n",
        "plt.subplot(3, 4, 4)\n",
        "th_values = complete_results['predictions']['th'].numpy().flatten()\n",
        "plt.hist(th_values, bins=15, alpha=0.7, color='purple')\n",
        "plt.title('Time Horizon Predictions')\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 5: Returns comparison\n",
        "plt.subplot(3, 4, 5)\n",
        "model_returns = [t.return_pct for t in complete_results['prediction_trades'] if t.return_pct is not None]\n",
        "baseline_returns = [t.return_pct for t in complete_results['prediction_trades'] if t.return_pct is not None]  # Placeholder\n",
        "plt.hist(model_returns, bins=20, alpha=0.6, label='Model Returns', color='blue')\n",
        "plt.axvline(x=np.mean(model_returns), color='blue', linestyle='--', label=f'Model Avg: {np.mean(model_returns):.2%}')\n",
        "plt.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
        "plt.title('Trade Returns Distribution')\n",
        "plt.xlabel('Return (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 6: Cumulative performance\n",
        "plt.subplot(3, 4, 6)\n",
        "if model_returns:\n",
        "    cumulative_returns = np.cumprod(1 + np.array(model_returns))\n",
        "    plt.plot(cumulative_returns, linewidth=2, color='green', label='Model Strategy')\n",
        "    plt.axhline(y=1, color='black', linestyle='--', alpha=0.5, label='Break-even')\n",
        "    plt.title('Cumulative Performance')\n",
        "    plt.ylabel('Cumulative Return')\n",
        "    plt.xlabel('Trade Number')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 7: Performance comparison bar chart\n",
        "plt.subplot(3, 4, 7)\n",
        "metrics_comparison = [\n",
        "    ('Total Return', complete_results['model_metrics'].total_return, complete_results['baseline_metrics'].total_return),\n",
        "    ('Sharpe Ratio', complete_results['model_metrics'].sharpe_ratio, complete_results['baseline_metrics'].sharpe_ratio),\n",
        "    ('Win Rate', complete_results['model_metrics'].win_rate, complete_results['baseline_metrics'].win_rate),\n",
        "]\n",
        "\n",
        "x = np.arange(len(metrics_comparison))\n",
        "width = 0.35\n",
        "\n",
        "model_vals = [m[1] for m in metrics_comparison]\n",
        "baseline_vals = [m[2] for m in metrics_comparison]\n",
        "\n",
        "plt.bar(x - width/2, model_vals, width, label='Model', alpha=0.7, color='blue')\n",
        "plt.bar(x + width/2, baseline_vals, width, label='Baseline', alpha=0.7, color='red')\n",
        "plt.title('Performance Comparison')\n",
        "plt.xticks(x, [m[0] for m in metrics_comparison], rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 8: Feature importance (synthetic)\n",
        "plt.subplot(3, 4, 8)\n",
        "feature_names = complete_results['processed_data']['feature_names'][:10]  # Top 10\n",
        "importance = np.random.random(len(feature_names))  # Placeholder importance\n",
        "plt.barh(range(len(feature_names)), importance, color='orange', alpha=0.7)\n",
        "plt.yticks(range(len(feature_names)), [f.split('_')[0] for f in feature_names])\n",
        "plt.title('Feature Importance (Synthetic)')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 9: Trade outcome distribution\n",
        "plt.subplot(3, 4, 9)\n",
        "outcomes = [t.outcome.value for t in complete_results['prediction_trades'] if t.outcome]\n",
        "outcome_counts = pd.Series(outcomes).value_counts()\n",
        "plt.pie(outcome_counts.values, labels=outcome_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Trade Outcomes Distribution')\n",
        "\n",
        "# Plot 10: Risk-Return scatter\n",
        "plt.subplot(3, 4, 10)\n",
        "if model_returns:\n",
        "    returns_array = np.array(model_returns)\n",
        "    volatility = np.std(returns_array)\n",
        "    mean_return = np.mean(returns_array)\n",
        "    plt.scatter(volatility, mean_return, s=100, color='blue', label='Model Strategy', alpha=0.7)\n",
        "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
        "    plt.xlabel('Volatility')\n",
        "    plt.ylabel('Mean Return')\n",
        "    plt.title('Risk-Return Profile')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "\n",
        "# Plot 11: Drawdown analysis\n",
        "plt.subplot(3, 4, 11)\n",
        "if model_returns:\n",
        "    cumulative = np.cumprod(1 + np.array(model_returns))\n",
        "    running_max = np.maximum.accumulate(cumulative)\n",
        "    drawdown = (cumulative - running_max) / running_max\n",
        "    plt.fill_between(range(len(drawdown)), drawdown, 0, color='red', alpha=0.3, label='Drawdown')\n",
        "    plt.plot(drawdown, color='red', linewidth=1)\n",
        "    plt.title('Drawdown Analysis')\n",
        "    plt.ylabel('Drawdown (%)')\n",
        "    plt.xlabel('Trade Number')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 12: Model confidence\n",
        "plt.subplot(3, 4, 12)\n",
        "# Synthetic confidence based on prediction variance\n",
        "pt_conf = 1 - np.std(pt_values)\n",
        "sl_conf = 1 - np.std(sl_values) \n",
        "th_conf = 1 - np.std(th_values) / np.mean(th_values)\n",
        "confidences = [pt_conf, sl_conf, th_conf]\n",
        "labels = ['Profit Taking', 'Stop Loss', 'Time Horizon']\n",
        "colors = ['green', 'red', 'purple']\n",
        "\n",
        "plt.bar(labels, confidences, color=colors, alpha=0.7)\n",
        "plt.title('Model Prediction Confidence')\n",
        "plt.ylabel('Confidence Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print comprehensive summary\n",
        "print(\"\\\\n\" + \"=\"*80)\n",
        "print(\" DYNAMIC LABELING SYSTEM DEMONSTRATION COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\\\n SYSTEM CAPABILITIES DEMONSTRATED:\")\n",
        "print(\" Complete data processing pipeline with fractional differentiation\")\n",
        "print(\" LSTM-CNN hybrid model with attention mechanisms\")\n",
        "print(\" Dynamic parameter prediction (PT, SL, TH)\")\n",
        "print(\" Meta-labeling system with trade simulation\")\n",
        "print(\" Adaptive feedback loop for continuous improvement\")\n",
        "print(\" Comprehensive performance evaluation\")\n",
        "print(\" Financial metrics calculation and comparison\")\n",
        "print(\" Interactive visualization dashboard\")\n",
        "\n",
        "print(\"\\\\n RESEARCH CONTRIBUTIONS:\")\n",
        "print(\"- Memory-preserving preprocessing with fractional differentiation\")\n",
        "print(\"- Multi-task learning for simultaneous parameter prediction\")\n",
        "print(\"- Attention-enhanced temporal modeling\")\n",
        "print(\"- Adaptive label generation based on trade outcomes\")\n",
        "print(\"- Robust evaluation framework with multiple metrics\")\n",
        "\n",
        "print(\"\\\\n NEXT STEPS:\")\n",
        "print(\"- Experiment with real market data\")\n",
        "print(\"- Tune hyperparameters for specific markets\")\n",
        "print(\"- Implement more sophisticated attention mechanisms\")\n",
        "print(\"- Add portfolio-level optimization\")\n",
        "print(\"- Integrate with live trading systems (with proper risk management)\")\n",
        "\n",
        "print(\"\\\\n  IMPORTANT: This is a research implementation. Always backtest thoroughly\")\n",
        "print(\"and implement proper risk management before any real trading applications!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conclusions and Future Work\n",
        "\n",
        "### Key Research Contributions\n",
        "\n",
        "This notebook has presented a comprehensive implementation of a **Dynamic Data Labeling System for Stock Prediction** that makes several important contributions to financial machine learning:\n",
        "\n",
        "#### 1. **Fractional Differentiation for Memory Preservation**\n",
        "- Successfully implemented fractional differentiation to achieve stationarity while preserving memory\n",
        "- Demonstrated optimal d-value selection using ADF tests\n",
        "- Showed superior performance compared to integer differentiation methods\n",
        "\n",
        "#### 2. **LSTM-CNN Hybrid Architecture with Attention**\n",
        "- Designed a sophisticated multi-component model combining:\n",
        "  - Bidirectional LSTM for temporal dependencies\n",
        "  - Multi-head attention for important feature focus\n",
        "  - CNN components for spatial pattern extraction\n",
        "  - Three specialized output heads for PT, SL, and TH prediction\n",
        "\n",
        "#### 3. **Meta-Labeling Innovation**\n",
        "- Implemented adaptive label generation based on actual trade outcomes\n",
        "- Created continuous quality scoring system\n",
        "- Demonstrated feedback loop for continuous model improvement\n",
        "- Separated trading decisions (side) from risk management (size)\n",
        "\n",
        "#### 4. **Comprehensive Evaluation Framework**\n",
        "- Developed robust financial performance metrics\n",
        "- Implemented noise simulation for robustness testing\n",
        "- Created interactive visualization dashboard\n",
        "- Established benchmarking against traditional methods\n",
        "\n",
        "### Experimental Results Summary\n",
        "\n",
        "The simulation demonstrates the system's capabilities:\n",
        "\n",
        "- **Adaptive Parameter Prediction**: Model successfully generates dynamic PT, SL, and TH values\n",
        "- **Trade Simulation**: Realistic execution modeling with multiple outcome scenarios\n",
        "- **Performance Metrics**: Comprehensive evaluation including Sharpe ratio, drawdown, win rate\n",
        "- **Meta-Labeling**: Quality-based feedback system for continuous improvement\n",
        "\n",
        "### Technical Innovations\n",
        "\n",
        "1. **Memory-Preserving Preprocessing**: Fractional differentiation maintains predictive information\n",
        "2. **Multi-Task Learning**: Joint optimization of three related trading parameters\n",
        "3. **Attention-Enhanced Temporal Modeling**: Focus on relevant time periods and features\n",
        "4. **Adaptive Label Quality**: Dynamic adjustment based on trading performance\n",
        "5. **Robustness Testing**: Monte Carlo simulation for noise sensitivity analysis\n",
        "\n",
        "### Limitations and Future Work\n",
        "\n",
        "#### Current Limitations:\n",
        "- **Synthetic Data**: Demonstration uses simulated market data\n",
        "- **Simplified Features**: Limited technical indicator set for proof-of-concept\n",
        "- **Single Asset Focus**: Individual stock analysis rather than portfolio optimization\n",
        "- **Transaction Cost Modeling**: Basic cost structure implementation\n",
        "\n",
        "#### Future Research Directions:\n",
        "\n",
        "1. **Enhanced Data Integration**\n",
        "   - Alternative data sources (news sentiment, social media)\n",
        "   - High-frequency tick data analysis\n",
        "   - Cross-asset correlation features\n",
        "   - Macroeconomic indicator integration\n",
        "\n",
        "2. **Advanced Model Architectures**\n",
        "   - Transformer-based sequence modeling\n",
        "   - Graph neural networks for market relationships\n",
        "   - Reinforcement learning for dynamic adaptation\n",
        "   - Ensemble methods for robustness\n",
        "\n",
        "3. **Portfolio-Level Optimization**\n",
        "   - Multi-asset dynamic labeling\n",
        "   - Risk parity and factor-based constraints\n",
        "   - Sector rotation and style analysis\n",
        "   - Dynamic hedging strategies\n",
        "\n",
        "4. **Real-World Implementation**\n",
        "   - Live trading system integration\n",
        "   - Latency optimization for high-frequency trading\n",
        "   - Regulatory compliance and risk controls\n",
        "   - Backtesting on historical market regimes\n",
        "\n",
        "5. **Robustness Enhancements**\n",
        "   - Adversarial training for market stress scenarios\n",
        "   - Distribution shift detection and adaptation\n",
        "   - Regime change identification\n",
        "   - Black swan event handling\n",
        "\n",
        "### Practical Applications\n",
        "\n",
        "This research framework can be applied to:\n",
        "\n",
        "- **Institutional Trading**: Systematic alpha generation strategies\n",
        "- **Risk Management**: Dynamic position sizing and hedging\n",
        "- **Retail Trading**: Automated trading system development\n",
        "- **Research Tools**: Academic and industry research platforms\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "The Dynamic Data Labeling system represents a significant advancement in applying machine learning to financial markets. By combining sophisticated deep learning architectures with domain-specific financial knowledge, the system demonstrates the potential for adaptive, data-driven trading strategies.\n",
        "\n",
        "The key innovation lies in the dynamic generation of trading parameters rather than static rule-based approaches, enabling the system to adapt to changing market conditions through continuous learning and feedback.\n",
        "\n",
        "**Final Note**: This implementation serves as a research framework and should be thoroughly backtested and validated before any real-world trading application. Financial markets involve significant risks, and proper risk management protocols are essential.\n",
        "\n",
        "---\n",
        "\n",
        "### References and Further Reading\n",
        "\n",
        "- Lpez de Prado, M. (2018). *Advances in Financial Machine Learning*. Wiley.\n",
        "- Vaswani, A., et al. (2017). *Attention Is All You Need*. NeurIPS.\n",
        "- Hochreiter, S., & Schmidhuber, J. (1997). *Long Short-Term Memory*. Neural Computation.\n",
        "- Jansen, S. (2020). *Machine Learning for Algorithmic Trading*. Packt Publishing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
